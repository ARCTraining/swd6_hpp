{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8eda9a1-0b12-40da-836e-96f0cebf1b25",
   "metadata": {},
   "source": [
    "# GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c16cb6-0cba-4fda-acf4-03b9a791df9a",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ARCTraining/swd6_hpp/blob/master/docs/06_GPUs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b93d5",
   "metadata": {},
   "source": [
    "```{note}\n",
    "This GPU lesson focuses primarily on NVIDIA CUDA which is a proprietary solution, and that there are open-source alternatives such as OpenCL.\n",
    "However, at present CUDA is the most used platform for GPU programming and therefore is included in this course.\n",
    "**Please note this means the following code will not run on Apple Macs at they do not have compatible hardware**\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c25a2-b675-456c-aa38-4b6fe8c1b701",
   "metadata": {},
   "source": [
    "```{admonition} Tip\n",
    ":class: tip \n",
    "If you're in COLAB or have a local CUDA GPU, you can follow along with this section (i.e., uncomment the GPU code bits).\n",
    "\n",
    "For those in COLAB, ensure the session is using a GPU by going to: Runtime > Change runtime type > Hardware accelerator = GPU.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c417818-9ff3-42f3-8e45-453b9a8e1c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "[GPUs (Graphics Processing Units)](https://en.wikipedia.org/wiki/Graphics_processing_unit) are optimised for numerical operations, while [CPUs (central processing units)](https://en.wikipedia.org/wiki/Central_processing_unit) perform general computation.\n",
    "\n",
    "Originally, GPUs handled computer graphics. However, they are now used to do a wide range of computations too. Hence, the term [General Purpose GPU (GPGPU)](https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units).  \n",
    "\n",
    "GPU hardware is designed for data parallelism, where high throughputs are achieved when the GPU is computing the same operations on many different elements at once.\n",
    "\n",
    "You could use other [types of accelerators](https://en.wikipedia.org/wiki/Hardware_acceleration) too, though we're not going to cover those here.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01cc79-c522-4fcf-8aae-9ab3790ddfdb",
   "metadata": {},
   "source": [
    "## [Numba for CUDA GPUs](http://numba.pydata.org/numba-doc/latest/cuda/index.html)\n",
    "\n",
    "Earlier we covered how Numba works on single CPUs with [`@njit`](https://numba.readthedocs.io/en/stable/glossary.html#term-nopython-mode) and multiple CPUs with `parallel = True`.\n",
    "\n",
    "As a recap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e522ad-e488-4eec-a720-bcd745f5dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "772aac51-cebd-45ae-b5a9-3fa688b7e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1.0e7, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5963d67-56fa-4cf5-bd7b-ad8917e08972",
   "metadata": {},
   "source": [
    "So, for a single CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d193f96-15b4-4872-8a80-81aa8803bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def my_serial_function_for_cpu(x):\n",
    "    return np.cos(x) ** 2 + np.sin(x) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f6fc56-d9ee-48d7-9187-3f53f68a0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 ms ± 2.38 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "my_serial_function_for_cpu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54839928-bd48-4501-ba46-4baff7d998fc",
   "metadata": {},
   "source": [
    "And, for multiple CPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bb1bc75-2961-4f4b-9442-b2329424be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def my_parallel_function_for_cpu(x):\n",
    "    return np.cos(x) ** 2 + np.sin(x) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45b0a3c-0fa4-4ceb-818b-bcea23df7538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.6 ms ± 7.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "my_parallel_function_for_cpu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b62ba-1689-419e-a3d3-aae3b72621b4",
   "metadata": {},
   "source": [
    "```{note}\n",
    "Here we used `njit` as this automates the parallelisation process.\n",
    "\n",
    "This is in contrast to `vectorize` where manual effort is required for parallelisation.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c35a4-ffbf-4a46-8915-454a777d0ac5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `vectorize` for GPUs\n",
    "\n",
    "Numba also works on [CUDA](https://developer.nvidia.com/how-to-cuda-python) GPUs using [`@vectorize`](https://numba.pydata.org/numba-doc/latest/user/vectorize.html) or [`@cuda.jit`](https://numba.readthedocs.io/en/stable/cuda/kernels.html).\n",
    "\n",
    "This is suitable for bigger data sizes (> 1 MB) and high compute intensities.\n",
    "\n",
    "This adds additional overhead due to moving data to and from GPUs ([memory management](https://numba.pydata.org/numba-doc/dev/cuda/memory.html)).\n",
    "\n",
    "Similar to our examples in the compiler lesson, we need to specify the types and target in the signature (i.e., the decorator arguments).\n",
    "\n",
    "Here, the types are specificed slightly differently i.e., output types(input types)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3221393-8fc2-4bfc-a620-2aca8bd3d768",
   "metadata": {},
   "source": [
    "```{attention}\n",
    "Not all NumPy code will work on the GPU. In the following example, we will need to use the `math` library instead.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52821ef6-0aec-4611-8160-1d12dcf43f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from numba import float32, vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6016dc81-e787-4d1c-8b8e-0d415571aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1.0e7, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6ca02f-c528-49b1-8bba-af3c45989406",
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129;43m@vectorize\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32(float32)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmy_serial_function_for_gpu\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/np/ufunc/decorators.py:131\u001b[0m, in \u001b[0;36mvectorize.<locals>.wrap\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    129\u001b[0m vec \u001b[38;5;241m=\u001b[39m Vectorize(func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sig \u001b[38;5;129;01min\u001b[39;00m ftylist:\n\u001b[0;32m--> 131\u001b[0m     \u001b[43mvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ftylist) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    133\u001b[0m     vec\u001b[38;5;241m.\u001b[39mdisable_compile()\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/np/ufunc/deviceufunc.py:391\u001b[0m, in \u001b[0;36mDeviceVectorize.add\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    388\u001b[0m funcname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpyfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    389\u001b[0m kernelsource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_kernel_source(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kernel_template,\n\u001b[1;32m    390\u001b[0m                                        devfnsig, funcname)\n\u001b[0;32m--> 391\u001b[0m corefn, return_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevfnsig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m glbl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_globals(corefn)\n\u001b[1;32m    393\u001b[0m sig \u001b[38;5;241m=\u001b[39m signature(types\u001b[38;5;241m.\u001b[39mvoid, \u001b[38;5;241m*\u001b[39m([a[:] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args] \u001b[38;5;241m+\u001b[39m [return_type[:]]))\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/vectorizers.py:202\u001b[0m, in \u001b[0;36mCUDAVectorize._compile_core\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_core\u001b[39m(\u001b[38;5;28mself\u001b[39m, sig):\n\u001b[0;32m--> 202\u001b[0m     cudevfn \u001b[38;5;241m=\u001b[39m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cudevfn, cudevfn\u001b[38;5;241m.\u001b[39moverloads[sig\u001b[38;5;241m.\u001b[39margs]\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mreturn_type\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/decorators.py:131\u001b[0m, in \u001b[0;36mjit.<locals>._jit\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m typeinfer\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m typeinfer\u001b[38;5;241m.\u001b[39mregister_dispatcher(disp):\n\u001b[0;32m--> 131\u001b[0m         \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43margtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     disp\u001b[38;5;241m.\u001b[39mcompile(argtypes)\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/dispatcher.py:882\u001b[0m, in \u001b[0;36mCUDADispatcher.compile_device\u001b[0;34m(self, args, return_type)\u001b[0m\n\u001b[1;32m    875\u001b[0m fastmath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetoptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastmath\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    877\u001b[0m nvvm_options \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetoptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastmath\u001b[39m\u001b[38;5;124m'\u001b[39m: fastmath\n\u001b[1;32m    880\u001b[0m }\n\u001b[0;32m--> 882\u001b[0m cc \u001b[38;5;241m=\u001b[39m \u001b[43mget_current_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_capability\n\u001b[1;32m    883\u001b[0m cres \u001b[38;5;241m=\u001b[39m compile_cuda(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_func, return_type, args,\n\u001b[1;32m    884\u001b[0m                     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m    885\u001b[0m                     lineinfo\u001b[38;5;241m=\u001b[39mlineinfo,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    888\u001b[0m                     nvvm_options\u001b[38;5;241m=\u001b[39mnvvm_options,\n\u001b[1;32m    889\u001b[0m                     cc\u001b[38;5;241m=\u001b[39mcc)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverloads[args] \u001b[38;5;241m=\u001b[39m cres\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/api.py:443\u001b[0m, in \u001b[0;36mget_current_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_current_device\u001b[39m():\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet current device associated with the current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcurrent_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py:220\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m(devnum)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_context\u001b[39m(devnum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the current device or use a device by device number, and\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    return the CUDA context.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py:138\u001b[0m, in \u001b[0;36m_Runtime.get_or_create_context\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    136\u001b[0m attached_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_attached_context()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attached_ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_or_create_context_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attached_ctx\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/cudadrv/devices.py:153\u001b[0m, in \u001b[0;36m_Runtime._get_or_create_context_uncached\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See also ``get_or_create_context(devnum)``.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03mThis version does not read the cache.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Try to get the active context in the CUDA stack or\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# activate GPU-0 with the primary context\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mget_active_context() \u001b[38;5;28;01mas\u001b[39;00m ac:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ac:\n\u001b[1;32m    155\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activate_context_for(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py:495\u001b[0m, in \u001b[0;36m_ActiveContext.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m drvapi\u001b[38;5;241m.\u001b[39mcu_context(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 495\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuCtxGetCurrent\u001b[49m(byref(hctx))\n\u001b[1;32m    496\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m hctx \u001b[38;5;28;01mif\u001b[39;00m hctx\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/swd6_hpp/lib/python3.9/site-packages/numba/cuda/cudadrv/driver.py:295\u001b[0m, in \u001b[0;36mDriver.__getattr__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CudaSupportError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at driver init: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    296\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_NV_BINDING:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cuda_python_wrap_fn(fname)\n",
      "\u001b[0;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "@vectorize([\"float32(float32)\"], target=\"cuda\")\n",
    "def my_serial_function_for_gpu(x):\n",
    "    return math.cos(x) ** 2 + math.sin(x) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ccf4a9-77c8-41ac-99c3-fcef0bf3d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# my_serial_function_for_gpu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f99144-e853-4ad6-89b2-7c75f7339113",
   "metadata": {},
   "source": [
    "Numba also supports generalized ufuncs (covered in the compiler lesson) on the GPU using [`guvectorize`](http://numba.pydata.org/numba-doc/latest/cuda/ufunc.html#generalized-cuda-ufuncs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6466145b-ae8a-48fc-bfe0-f41e47e117b9",
   "metadata": {},
   "source": [
    "### Custom CUDA kernels\n",
    "\n",
    "Kernel functions are GPU functions called from CPU code.\n",
    "\n",
    "Kernels cannot explicitly return a value. Instead, all result data must be written to an array passed to the function (e.g., called `out`). This array can then be transferred back to the CPU.\n",
    "\n",
    "Kernels work over a grid of threads. This grid needs to be defined in terms of the number of blocks in the grid and the number of threads per block. The indices of this grid are used to add values to the `out` array. The indices can be found using [`cuda.grid()`](https://numba.pydata.org/numba-doc/dev/cuda-reference/kernel.html#numba.cuda.grid).\n",
    "\n",
    "CUDA kernels are compiled using the [`numba.cuda.jit`](https://numba.pydata.org/numba-doc/dev/cuda-reference/kernel.html#numba.cuda.jit) decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d79a8-bbe9-495e-b8b4-260b4db80155",
   "metadata": {},
   "source": [
    "```{note}\n",
    "`numba.cuda.jit` is different to `numba.jit`, which is for CPUs.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f44a6-644d-4be2-bcb6-b4a7e0269122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd244d7-130f-44f1-9b0e-0636e715dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1aaac-a458-478f-a986-9a66eed89d47",
   "metadata": {},
   "source": [
    "This should return a message similar to:  \n",
    "<Managed Device 0>.\n",
    "\n",
    "You can also run the bash command `nvidia-smi` within the IPython cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359a0c10-157c-41eb-89d6-8e8ef870014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6250f7-46ea-42b8-9240-b41fd3b7f771",
   "metadata": {},
   "source": [
    "This returns something like the table below. This shows we have access to a [NVIDIA Tesla T4 GPU](https://www.nvidia.com/en-gb/data-center/tesla-t4/).\n",
    "\n",
    "```bash\n",
    "Tue Feb 22 13:59:03 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
    "| N/A   66C    P0    30W /  70W |    144MiB / 15109MiB |      0%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ccf896-c980-4923-a750-7c01646afbdd",
   "metadata": {},
   "source": [
    "So, a simple example to add two numbers together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75ced9-32a4-44fd-a0a1-b33f4ff9dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @cuda.jit\n",
    "# def add_kernel(x, y, out):\n",
    "#     index = cuda.grid(1)\n",
    "#     out[index] = x[index] + y[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d49dbb-228c-403a-a91c-c0a51af88e3e",
   "metadata": {},
   "source": [
    "Let's define some input variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0002ff-4460-4bfb-8c29-cb578e0d263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 4096\n",
    "# x = np.arange(n).astype(np.int32) # [0...4095] on the host (CPU)\n",
    "# y = np.ones_like(x)               # [1...1] on the host (CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56400925-e246-4d6f-af03-bcd734b64f6e",
   "metadata": {},
   "source": [
    "Now, let's move these input variables from the host (CPU) to the device (GPU) for the work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661bbb47-08ab-4836-acd7-f1dad5d94f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_on_device = cuda.to_device(x)\n",
    "# y_on_device = cuda.to_device(y)\n",
    "# out_on_device = cuda.device_array_like(x_on_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795dad6c-0f97-4594-afdf-de4fee6d0448",
   "metadata": {},
   "source": [
    "Now, we [choose the block size](https://numba.pydata.org/numba-doc/latest/cuda/kernels.html#choosing-the-block-size), by defining how many blocks are in the grid and how many threads are in each of those blocks.\n",
    "\n",
    "These two numbers multipled together is the size of the grid (for our 1D example).\n",
    "\n",
    "![cuda_grid.png](images/cuda_grid.png)  \n",
    "\n",
    "*[Image source](https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/)*\n",
    "\n",
    "Some rules of thumb are:\n",
    "- Blocks per grid should be a multiple of 32.\n",
    "- Threads per block should be a multiple of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6b274-e053-42f8-9b37-36f10516c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocks_per_grid = 32\n",
    "# threads_per_block = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a03f0f-a0db-4502-834c-0174258b5774",
   "metadata": {},
   "source": [
    "Now, we can call the kernel function.\n",
    "\n",
    "First, add the grid size arguments.\n",
    "\n",
    "Then, we pass the input/output variables as arguments to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b8f3d-7c39-4ada-b553-5dd93a925afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_kernel[blocks_per_grid, threads_per_block](x_on_device, y_on_device, out_on_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd73a6-161f-49f9-b5a3-698c4d313527",
   "metadata": {},
   "source": [
    "As these CUDA kernels don't return a value, we can synchronise the device (GPU) back to the host (CPU) to get the result back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544215f1-b446-4a68-a41f-1d41c6d2964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda.synchronize()\n",
    "# print(out_on_device.copy_to_host())\n",
    "# # Should be [   1    2    3 ... 4094 4095 4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e915bd-1abd-4f87-9437-5e51abb2625d",
   "metadata": {},
   "source": [
    "For more information on CUDA, see the training courses:\n",
    "\n",
    "- [HPC5: Introduction to GPU programming with CUDA](https://arc.leeds.ac.uk/training/courses/hpc5/)\n",
    "- NVIDIA workshop on [Fundamentals of Accelerated Computing with CUDA Python](https://www.nvidia.com/en-us/training/instructor-led-workshops/fundamentals-of-accelerated-computing-with-cuda-python/)\n",
    "    - Detailed look at [custom CUDA kernels](https://numba.pydata.org/numba-doc/dev/cuda/kernels.html) and [GPU memory management](https://numba.pydata.org/numba-doc/dev/cuda/memory.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b679d8-1df4-4cbb-a7ad-161e8ea4658d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [RAPIDS](https://developer.nvidia.com/rapids)\n",
    "\n",
    "RAPIDS is a range of accelerated data science libraries from NVIDIA.\n",
    "\n",
    "There are a wide variety of tools matching up to familiar libraries:\n",
    "\n",
    "- Arrays and matrices\n",
    "  - [cuPy](https://cupy.dev/) for NumPy and SciPy\n",
    "- Tabular data\n",
    "    - [cuDF](https://docs.rapids.ai/api/cudf/stable/) for Pandas\n",
    "- Machine learning\n",
    "    - [cuML](https://docs.rapids.ai/api/cuml/stable/) for scikit-learn\n",
    "    - [XGBoost](https://rapids.ai/xgboost.html) on GPUs\n",
    "- Graphs and networks\n",
    "    - [cuGraph](https://docs.rapids.ai/api/cugraph/stable/) for [NetworkX](https://networkx.org/)\n",
    "- Multiple GPUs\n",
    "    - [Dask with CUDA](https://rapids.ai/dask.html), cuDF, cuML, and others.\n",
    "    - [Dask-MPI with GPUs](http://mpi.dask.org/en/latest/gpu.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52016c4b-e769-4a0d-ae9a-a223bc352f89",
   "metadata": {},
   "source": [
    "### [cuPy](https://cupy.dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a57d09-8e88-4485-a136-e799f053b750",
   "metadata": {},
   "source": [
    "**NumPy for the CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121cfce7-9ceb-442c-94e7-683f0abc8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a749fe7-a4e7-417c-a25f-abea5e6075ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cpu = np.random.rand(1_000, 1_000)\n",
    "y_cpu = np.random.rand(1_000, 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19fd453-a371-4bed-86bd-8b9408075001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.2 ms ± 9.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z_cpu = np.dot(x_cpu, y_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dff284f-ec8b-4774-851a-1941325c3a67",
   "metadata": {},
   "source": [
    "**CuPy for the GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d343d4-95d8-4007-9258-25c9f119f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055b298-a374-48a9-8d99-0b1c1be10117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_gpu = cp.random.rand(1_000, 1_000)\n",
    "# y_gpu = cp.random.rand(1_000, 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6e3ae-11be-49fd-b3f0-04230d251f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# z_gpu = cp.dot(x_gpu, y_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5185093-82f3-4af2-b5d8-1d702ba81c0a",
   "metadata": {},
   "source": [
    "You can move arrays between the CPU and GPU as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1237b-5dcf-4094-b52c-2cbbc6a5a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_gpu = cp.asarray(z_cpu)  # from cpu to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c08dd-618d-4e37-8249-232cfafbf861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_cpu = cp.asnumpy(z_gpu)  # from gpu to cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e63d3f-4113-469d-b895-b36319cb4843",
   "metadata": {},
   "source": [
    "For more information on RAPIDS, see the training courses:\n",
    "\n",
    "- NVIDIA workshop on [Fundamentals of Accelerated Data Science (RAPIDS)](https://www.nvidia.com/en-us/training/instructor-led-workshops/fundamentals-of-accelerated-data-science/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68fa212-6b88-467b-ae53-75c5f64109f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Diagnostics\n",
    "\n",
    "Similar to the Dask Dashboard, NVIDIA has a GPU Dashboard called [`NVDashboard`](https://github.com/rapidsai/jupyterlab-nvdashboard).\n",
    "\n",
    "These real-time diagnostics are provided via a Bokeh server and a Jupyter Lab extension.  \n",
    "\n",
    "They are a great way to manage your GPU utilisation, resources, throughput, and more.  \n",
    "\n",
    "More information is [here](https://developer.nvidia.com/blog/gpu-dashboards-in-jupyter-lab/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a757322-fcee-4983-83a8-dbb3fdbf1eaa",
   "metadata": {},
   "source": [
    "![SegmentLocal](images/NVIDIA_GPUDashboard.gif \"segment\")\n",
    "\n",
    "*[Image source](https://developer.nvidia.com/blog/gpu-dashboards-in-jupyter-lab/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1731ac1-bece-4685-bb95-19cb74dff0f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [JAX](https://jax.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "JAX enables:\n",
    "\n",
    "- NumPy on the CPU and GPU (via [XLA, Accelerated Linear Algebra](https://www.tensorflow.org/xla), a compiler for linear algebra).\n",
    "- Automatic differentiation of native Python and NumPy code (via [Autograd](https://github.com/hips/autograd)).\n",
    "- [`Jit`](https://jax.readthedocs.io/en/latest/_autosummary/jax.jit.html#jax.jit) compiler to speed up code.\n",
    "- Automatic vectorisation through [`vmap`](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html#jax.vmap)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba5125-0835-4d9d-a0d8-3f4fd5b1bfda",
   "metadata": {},
   "source": [
    "### JAX can replace NumPy for GPUs\n",
    "\n",
    "If it can't find a GPU, then it will fall back to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36582cd8-9fc1-4c2e-8f1d-69260c866ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c41d8ca6-e955-4efd-a347-e88fa1da9d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = np.arange(10)\n",
    "print(type(x_np))\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f36146e6-1221-4213-bee1-81bb917a6e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 16:02:15.867936: W external/org_tensorflow/tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-25 16:02:15.867960: W external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.DeviceArray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_jnp = jnp.arange(10)\n",
    "print(type(x_jnp))\n",
    "x_jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad1727-d224-408c-8841-6b71072f0ac1",
   "metadata": {},
   "source": [
    "However, there are some differences between JAX and NumPy.\n",
    "\n",
    "For example, [JAX arrays are immutable](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html#jax-vs-numpy) (i.e., you can't change them once their made)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f54b7e6a-59eb-4865-b6cf-495c7fb9adc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1,  2,  3,  4,  5,  6,  7,  8,  9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np[0] = 10\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20eb3392-f346-4d4b-9759-87bae0af254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, you can't change JAX arrays once their made.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x_jnp[0] = 10\n",
    "    print(x_jnp)\n",
    "except TypeError:\n",
    "    print(\"Sorry, you can't change JAX arrays once their made.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded3d70-db91-495a-9fc4-a204118dad53",
   "metadata": {},
   "source": [
    "Instead, you can create a copy with the change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f57cddc-c316-4d41-b59e-6babcd9e6286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([10,  1,  2,  3,  4,  5,  6,  7,  8,  9], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_x_jnp = x_jnp.at[0].set(10)\n",
    "updated_x_jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5cf7ed-466b-4671-8a66-52c0ae3940e5",
   "metadata": {},
   "source": [
    "Also, [random arrays are created differently](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#random-numbers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "655213c0-3cf0-45ed-b4e9-12affaeefbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.random.normal(size=(3_000, 3_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f0bd963-e9f8-4e5d-9226-2eb536313527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4836eaf-2762-448a-bdfc-0ffc6dcb8379",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_key = random.PRNGKey(0)\n",
    "x_jnp = random.normal(random_key, (3_000, 3_000), dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ccd766-c662-4a2b-a19c-e1892e1834f2",
   "metadata": {},
   "source": [
    "Now, you could multiply arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4634424a-891f-463a-8971-ad94ce4342a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 ms ± 18.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.dot(x_np, x_np.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "768e6f33-0965-47ff-a990-e898b4f6fc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187 ms ± 1.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.dot(x_jnp, x_jnp.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7beee-b452-4c42-9bad-71321a743593",
   "metadata": {},
   "source": [
    "By default, this will transfer data from the host (CPU) to the device (GPU).\n",
    "\n",
    "To avoid this and [put data](https://jax.readthedocs.io/en/latest/_autosummary/jax.device_put.html#jax.device_put) onto the device (GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c64ce34a-03fe-4f93-a20a-2a389ef475e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import device_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe1795fd-dd2a-463e-8536-6bc616357836",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_jnp = device_put(x_jnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd3e9a45-7c08-44ab-b5d0-8254a059a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 ms ± 1.55 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.dot(x_jnp, x_jnp.T).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f22e3a-a0a6-4d80-ad0a-8ce53b7d6ca7",
   "metadata": {},
   "source": [
    "In general, the speed comparison between JAX and NumPy is complicated and depends on a variety of things ([read more here](https://jax.readthedocs.io/en/latest/faq.html#faq-jax-vs-numpy))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707cfb48-7062-44ed-90b8-58402f403a3e",
   "metadata": {},
   "source": [
    "### [`@jit`](https://jax.readthedocs.io/en/latest/_autosummary/jax.jit.html#jax.jit) compiler\n",
    "\n",
    "Let's see an example of using the JAX `@jit` compiler to speed up a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2636be82-557e-4db3-a962-e327c359548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e73fb191-dec0-48cb-90e0-a9e64ed7004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.normal(random_key, (1_000_000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36de490-9c9b-4254-be90-2a8e3869ef5a",
   "metadata": {},
   "source": [
    "Here were using an example for the [SELU (Scaled Exponential Linear Unit)](https://arxiv.org/pdf/1706.02515v5.pdf) activation function (*don't worry what this is*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b312cc30-8f45-434c-9f27-bc98db6ff456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slow_selu(x, alpha=1.67, lmbda=1.05):\n",
    "    return lmbda * jnp.where(x > 0, x, alpha * jnp.exp(x) - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e4f6587-693a-44ee-b391-2fa10ded4683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12 ms ± 48.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "slow_selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6320d60b-79cc-44a0-9b29-ee2cdec36021",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_selu = jit(slow_selu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a167bcc-e396-4d18-820c-c798fd592c66",
   "metadata": {},
   "source": [
    "Remember from our compiler lesson, that the first call to a JIT-decorated function compiles it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f95db17a-483a-429b-8b52-499e6657df7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "fast_selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12b34c-d88b-470c-be89-fd3ddc8cb060",
   "metadata": {},
   "source": [
    "Then all subsequent calls to it use the cached, fast version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2299db5-52c8-4038-b19c-cec5c0b68b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "fast_selu(x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc8d4b-c9be-46ff-8722-45fe11e628c0",
   "metadata": {},
   "source": [
    "### Automatic vectorisation with [`vmap()`](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html#jax.vmap)\n",
    "\n",
    "`vmap` maps a function over array axes.\n",
    "\n",
    "This pushes the map loop lower down for better performance.\n",
    "\n",
    "Let's see an example of multiplying a matrix by a batch of vectors (*don't worry what this function does, just focus on the JAX bits*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3db9c0e3-3bd3-4028-9a9b-05cc13342d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5c5450c-f16c-4b2c-acae-c9c1c99c1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = random.normal(random_key, (150, 100))\n",
    "batch_vectors = random.normal(random_key, (10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0dc99d11-b24c-4e4a-86e5-5355fd43c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplying_matrix_by_vector(vector):\n",
    "    return jnp.dot(matrix, vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2e2e59-dd10-4a8f-a6b5-f7f672b02344",
   "metadata": {},
   "source": [
    "So, first apply this function in a simple batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7eda2018-457d-4be6-816a-fee38c11e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_batch(batch_vectors):\n",
    "    return jnp.stack([multiplying_matrix_by_vector(vector) for vector in batch_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3e4e571-6e48-4fb2-90f9-8a7956335695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726 µs ± 32 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit simple_batch(batch_vectors).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a244fe-8ec8-4afe-a1a3-9a5094d940fb",
   "metadata": {},
   "source": [
    "Now, let's instead use a `vmap` batch to map the function over the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1723771-39ca-4e20-9408-c9b87019b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmap_batch(batch_vectors):\n",
    "    return vmap(multiplying_matrix_by_vector)(batch_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "228ffbae-4bf7-47da-b040-38881ebe36c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 µs ± 19.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit vmap_batch(batch_vectors).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb38b54b-f68a-46fa-92c7-5a16d7cd9d5e",
   "metadata": {},
   "source": [
    "And, let's get even more performance by combining this with the `jit` compiler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da06e24e-8260-44c9-b7e4-6acaceeb63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def faster_vmap_batch(batch_vectors):\n",
    "    return vmap(multiplying_matrix_by_vector)(batch_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f844b6c2-cb60-4d61-80b4-076f1c28a540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.1 µs ± 1.88 µs per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit faster_vmap_batch(batch_vectors).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a3cbf-26c8-48f9-b27b-ca334d57f192",
   "metadata": {},
   "source": [
    "There is lots more useful information in the [documentation](https://jax.readthedocs.io/en/latest/index.html), such as [a range of tutorials](https://jax.readthedocs.io/en/latest/jax-101/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7457cd-16eb-4775-8de7-afb1ef15a2d4",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3210104b-8e88-4ad5-941b-c4a58fc97589",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20899625-7042-4e21-ba4d-6d59551a1a7b",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 1\n",
    "\n",
    "In general, what kind of tasks are GPUs faster than CPUs for, and why?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde2bf0-2f36-403c-baf9-4022d80e1285",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 2\n",
    "\n",
    "What Numba decorators can you use to offload a function to GPUs?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca4ae3-9964-4111-a78f-5a6b7c6110fb",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 3\n",
    "\n",
    "How would you vectorize the the following function for GPUs?  \n",
    "\n",
    "`def my_serial_function_for_gpu(x):`  \n",
    "`    return math.cos(x) ** 2 + math.sin(x) ** 2`  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cac02-8ce0-43ff-8f93-684acafc21a9",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 4\n",
    "\n",
    "What are ways you can check if your Python environment has access to a GPU?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d616d927-f457-4fb0-a7d8-4be483997a13",
   "metadata": {},
   "source": [
    "```{admonition} Exercise 5\n",
    "\n",
    "If you wanted to do NumPy style work on GPUs, could you use:\n",
    "\n",
    "- cuPy\n",
    "- JAX\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5490d7e3-bd1a-4294-bfbc-4739145b4467",
   "metadata": {},
   "source": [
    "## {ref}`Solutions <gpus>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf1ca3-141b-4ec2-b8e2-d8712d4d8f9e",
   "metadata": {},
   "source": [
    "## Key Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec61e0a1-481e-45be-99cc-6885baa6a725",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "- [x] _Use [CUDA/Numba](https://developer.nvidia.com/how-to-cuda-python), [RAPIDS](https://developer.nvidia.com/rapids), and [JAX](https://jax.readthedocs.io/en/latest/index.html) to write custom data science code for CUDA GPUs._\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea113ee0-9ed3-4b77-9f5f-eca6600f7d22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Further information\n",
    "\n",
    "### Good practises\n",
    "\n",
    "- Test out ideas on CPUs first, before moving to expensive GPUs.\n",
    "- Consider whether the calculation is worth the additional overhead of sending data to and from the GPU.\n",
    "- Minimise data transfers between the host (CPU) and the device (GPU).\n",
    "\n",
    "### Other options\n",
    "\n",
    "- [pycuda](https://documen.tician.de/pycuda/)\n",
    "    - An alternative to Numba for accessing NVIDIA's CUDA GPUs.\n",
    "- [cuNumeric](https://developer.nvidia.com/cunumeric)\n",
    "    - A swap-out replacement for NumPy from NVIDIA for distributed GPUs.\n",
    "    - Early stages of development.\n",
    "    - Requires a separate interperter to run (Legate).\n",
    "- Many libraries can use GPUs automatically if they can detect one e.g., [`TensorFlow`](https://www.tensorflow.org/install/gpu) and [`PyTorch`](https://pytorch.org/docs/stable/notes/cuda.html).\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [CuPy - Sean Farley](https://www.youtube.com/watch?v=_AKDqw6li58), PyBay 2019.  \n",
    "- [cuDF - Mark Harris](https://www.youtube.com/watch?v=lV7rtDW94do), PyCon AU 2019.  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1ffad78e3b53a26aeabe29bd69865e9fcde2eed64638bf28084d4e5d53534f3"
  },
  "kernelspec": {
   "display_name": "swd6_hpp",
   "language": "python",
   "name": "swd6_hpp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}