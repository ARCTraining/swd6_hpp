{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SWD 6.3 More on Numba.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvzEAU+TjdXuE6cRbB3a5X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"SUqdx82KXR45"},"source":["## SWD 6 Notebook 3: More on Numba\n","\n","[Official documentation](https://numba.pydata.org/)\n","\n","Although Numba appears to give a great speed-up for very little programming overhead (compared to Cython, say) we need to understand that it works best in certain scenarios:\n","\n","* code that is numerically oriented\n","* code that makes a lot of use of numpy arrays and numpy functions\n","* code that has a lot of loops\n","\n","It won't work at all well with codes:\n","\n","* that handle a lot of strings\n","* that uses Pandas\n","\n","Cython however will give some speedup in almost all circumstances whereas Numba will optimise most effectively numerical codes as described above.\n","\n","Numba will work with:\n","\n","* **OS**: Windows (32 and 64 bit), OSX and Linux (32 and 64 bit)\n","* **Architecture**: x86, x86_64, ppc64le. Experimental on armv7l, armv8l (aarch64).\n","* **GPUs**: Nvidia CUDA. Experimental on AMD ROC.\n","\n","* CPython\n","* NumPy 1.15 - latest\n"]},{"cell_type":"markdown","metadata":{"id":"708SQLI8-Qss"},"source":["## A first Numba example\n","\n","As we mentioned earlier, Numba is most effective on numerically intensive codes. From the Numba documentation:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcL9o0dkXPun","executionInfo":{"status":"ok","timestamp":1622811659197,"user_tz":-60,"elapsed":1758,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh6.googleusercontent.com/-JtcwYg3Zxkg/AAAAAAAAAAI/AAAAAAAAA3I/oPac6aA6UhM/s64/photo.jpg","userId":"14343904755675752784"}},"outputId":"d2e267f4-160d-4ec5-9a7b-b76a6ba2e386"},"source":["%%timeit\n","from numba import jit\n","import numpy as np\n","\n","x = np.arange(100).reshape(10, 10)\n","\n","@jit(nopython=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n","def go_fast(a): # Function is compiled to machine code when called the first time\n","    trace = 0.0\n","    for i in range(a.shape[0]):   # Numba likes loops\n","        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n","    return a + trace              # Numba likes NumPy broadcasting\n","\n","go_fast(x)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 loop, best of 5: 218 ms per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TwKp4lE7-p1H"},"source":["Numba's `@jit` decorator defines a function to be compiled by Numba.\n","\n","It operates in two modes:\n","* `nopython` mode\n","* `object` mode\n","\n","In `nopython` mode, Numba will compile the decorated function without any involvement of the Python interpreter. This should give the best performance and is the preferred model.\n","\n","The fallback is `object` mode. Here, Numba will attempt to compile loops into machine code functions but for everything else it will fall back to the Python interpreter. Although this will often give some speedup it isn't the optimal model and should be avoided."]},{"cell_type":"markdown","metadata":{"id":"0lBRPKjUAVGf"},"source":["## Measuring performance\n","\n","In the timed cells above, you may have seen some odd results. Perhaps the Numba code seemed slower?\n","\n","We need to understand just how Numba works.\n","\n","* The first time Numba visits a function, it will compile it for the argument types given before it runs the machine code version.\n","* This first compilation adds an overhead\n","* **Subsequent** runs of the function use the compiled version and will be much faster\n","\n","We can see this in the code below:"]},{"cell_type":"code","metadata":{"id":"KtIqzH5X-oh7"},"source":["from numba import jit\n","import numpy as np\n","import time\n","\n","@jit(nopython=True)\n","def go_fast(a): # Function is compiled and runs in machine code\n","    trace = 0.0\n","    for i in range(a.shape[0]):\n","        trace += np.tanh(a[i, i])\n","    return a + trace"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LfM0TsYTFJpt"},"source":["x = np.arange(100).reshape(10, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsaMrQUuFvBs"},"source":["On the first run, there's a compilation overhead so the function takes a while to run:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBUGiRdoBQOn","executionInfo":{"status":"ok","timestamp":1622811176891,"user_tz":-60,"elapsed":622,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh6.googleusercontent.com/-JtcwYg3Zxkg/AAAAAAAAAAI/AAAAAAAAA3I/oPac6aA6UhM/s64/photo.jpg","userId":"14343904755675752784"}},"outputId":"894189ba-29d3-42ac-f303-26f197f3e5d7"},"source":["%%timeit -n 1 -r 1\n","go_fast(x)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 loop, best of 1: 444 ms per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"B6MFkEH-F9Jj"},"source":["However on second and subsequent calls to the function the compiled version is used and it's **much** faster."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYQuPk_nBbnl","executionInfo":{"status":"ok","timestamp":1622811247891,"user_tz":-60,"elapsed":180,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh6.googleusercontent.com/-JtcwYg3Zxkg/AAAAAAAAAAI/AAAAAAAAA3I/oPac6aA6UhM/s64/photo.jpg","userId":"14343904755675752784"}},"outputId":"5ae47780-dc05-4369-fc1a-449414d1c969"},"source":["%%timeit -n 1 -r 1\n","go_fast(x)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 loop, best of 1: 27.5 µs per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z_E9NwCdGL7X"},"source":["On my runs, for example:\n","\n","| First run | Second run |\n","|-----------|------------|\n","| 444 ms    | 27.5 µs    |"]},{"cell_type":"markdown","metadata":{"id":"FM7N3gYbG0yX"},"source":["## A more involved example\n","\n","In the following code example, we use several numba concepts:\n","\n","**nopython mode** [Recommended and Best Practice mode]. \n","In nopython mode, the decorated function will be run entirely without the involvement of a Python interpreter. For this to work native python objects have to be replaced with Numba supported data structures/types.\n","Use @njit and @jit(nopython=True) decorators to Numba JIT compile your functions\n","\n","**Object mode**   \n","In object mode, Numba identifies loops with only nopython operations and compiles them into machine code. The rest of the code will run using a Python interpreter. Use @jit to invoke object model compilation\n","\n","**Run code in Parallel**.  \n","Invoked by adding `parallel=True` in `@njit` , `@jit` decorators. Numba allows you to explicitly run code in parallel by the use of `prange` keyword. Numba automatically optimises your code when run in parallel.\n","These optimisations can be viewed by using `numba_func.parallel_diagnostics(level=4)` level refers to the level of details. 1 is for minimum and 4 is for maximum."]},{"cell_type":"code","metadata":{"id":"QNPlFbl2HmAY","executionInfo":{"status":"ok","timestamp":1623147865092,"user_tz":-60,"elapsed":319,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}}},"source":["from numba import njit\n","from numba.np.ufunc import parallel\n","import numpy as np\n","from time import perf_counter\n","from numba import prange # to force explicit parallel runs of the loop\n","# if using notebook replace this with %%timeit\n","\n","# example 1 Native Python code\n","def trace_normal(a): # native python function\n","  trace = 0.0\n","  for i in range(a.shape[0]):\n","    trace += a[i, i]\n","\n","  return a + trace\n","\n","# example 2 numpy code\n","# baseline operation that we will replicate in numba\n","def pure_numpy_trace(a):\n","  return (np.trace(a) + a)\n","\n","# Example 3 numba optimized code\n","@njit\n","def trace_numba(a): # Function is compiled to machine code when called the first time\n","  trace = 0.0\n","  for i in range(a.shape[0]): # Numba likes loops\n","    trace += a[i, i] # Numba likes NumPy functions\n","  return a + trace # Numba likes NumPy broadcasting\n","\n","@njit(parallel=True)\n","def trace_numba_parallel(a):\n","  trace = 0.0\n","  for i in range(a.shape[0]):\n","    trace += a[i, i]\n","  return a + trace\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzNeozDSIDdx","executionInfo":{"status":"ok","timestamp":1623147743921,"user_tz":-60,"elapsed":291,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}}},"source":["# Create some large arrays\n","large_x = np.arange(1000000).reshape(1000, 1000)\n","small_x = np.arange(10000).reshape(100, 100)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkXF2QNuItwX","executionInfo":{"status":"ok","timestamp":1623147765739,"user_tz":-60,"elapsed":10678,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}},"outputId":"17d62324-ff3f-4447-a088-5db40747bf64"},"source":["# Use timeit to return some results\n","%%timeit \n","trace_normal(large_x)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1000 loops, best of 5: 1.63 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBFs0ajWJamC","executionInfo":{"status":"ok","timestamp":1623147800354,"user_tz":-60,"elapsed":3277,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}},"outputId":"0ec92456-f7d4-41f4-a606-4b31e1258f52"},"source":["%%timeit \n","trace_normal(small_x)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["The slowest run took 32.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n","10000 loops, best of 5: 46.8 µs per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xr9zoEIJgNx","executionInfo":{"status":"ok","timestamp":1623147880018,"user_tz":-60,"elapsed":6762,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}},"outputId":"beda3393-a9d2-4d95-ce32-c324ca69d8f8"},"source":["%%timeit \n","pure_numpy_trace(large_x)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["The slowest run took 8.32 times longer than the fastest. This could mean that an intermediate result is being cached.\n","1000 loops, best of 5: 981 µs per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r_rPDpMsKANr"},"source":["## Exercise: \n","\n","Try timing all three versions of the code with both large and small arrays.\n","\n","What are your observations?"]},{"cell_type":"markdown","metadata":{"id":"hz33P-zYDuqK"},"source":["## Signatures\n","\n","It is also possible to specify the signature of the Numba function. A **function signature** describes the types of the arguments and the return type of the function. This can produce slightly faster code as the compiler does not need to infer the types. However the function is no longer able to accept other types.\n","\n"]},{"cell_type":"code","metadata":{"id":"QLyv8AzIFTWL","executionInfo":{"status":"ok","timestamp":1623146733971,"user_tz":-60,"elapsed":1408,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}}},"source":["from numba import jit, int32, float64\n","\n","@jit(float64(int32, int32))\n","def f(x, y):\n","    # A somewhat trivial example\n","    return (x + y) / 3.14"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ushuGBrOFebf"},"source":["In this example, `float64(int32, int32)` is the function’s signature specifying a function that takes two 32-bit integer arguments and returns a double precision float. Numba provides a shorthand notation, so the same signature can be specified as `f8(i4, i4)`.\n","\n","The specialisation will be compiled by the @jit decorator, and no other specialization will be allowed. This is useful if you want fine-grained control over types chosen by the compiler (for example, to use single-precision floats).\n","\n","If you omit the return type, e.g. by writing (int32, int32) instead of float64(int32, int32), Numba will try to infer it for you. Function signatures can also be strings, and you can pass several of them as a list; see the `numba.jit()` documentation for more details."]},{"cell_type":"markdown","metadata":{"id":"ItpbZ4CFFoJ3"},"source":["The new compiled function gives the expected results."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hfMab32WFXwq","executionInfo":{"status":"ok","timestamp":1623146827952,"user_tz":-60,"elapsed":212,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}},"outputId":"da94c5ee-6904-4482-d796-9cadbc99036b"},"source":["f(1, 3)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.2738853503184713"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"BQexRVuxFycf"},"source":["But passing reals will cause an unexpected result:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TU_ARNIkFw43","executionInfo":{"status":"ok","timestamp":1623146911052,"user_tz":-60,"elapsed":258,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}},"outputId":"2cd132fd-7fa2-49ac-98f4-9cc7b1442b1e"},"source":["f(1.1, 3.2)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.2738853503184713"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"JughPmo_KQPf"},"source":["For ease of use and further comparison, numba also retains a copy of the uncompiled versions of functions.\n","\n","This can be accessed via the `.py_func` attribute of the function:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9GUrDZKF6k0","executionInfo":{"status":"ok","timestamp":1623148148513,"user_tz":-60,"elapsed":503,"user":{"displayName":"Martin Callaghan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GisklH0uOUyh5WQyi5z1Iu2Q5UJJzq5b3tc4W99kA=s64","userId":"14343904755675752784"}},"outputId":"d56df6b7-cee1-401a-e729-120927dedb76"},"source":["f.py_func(1.1, 3.2)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.3694267515923568"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"JMoivGNxK2W1"},"source":["which gives a more expected results."]},{"cell_type":"markdown","metadata":{"id":"olh7SsMIOP6-"},"source":["## Exercise:\n","\n","Using the `julia.py` code in the Github repository, compare it;s execution speed using a range of numba tools.\n","\n","What are your observations?"]},{"cell_type":"code","metadata":{"id":"L4u4oUPKOPlC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uAa9la-CKzPr"},"source":[""],"execution_count":null,"outputs":[]}]}